% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...
\usepackage{amsmath,epsfig}
\usepackage{amsthm, amssymb}

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% The "real" document content comes below...

\title{LING773 - Negotiations Project Proposal}
\author{Peng Ye, Youngil Kim, Olivia Buzek}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed

\begin{document}
\maketitle

\section{Introduction} % by Olivia

In this project, we will use feature engineering to better predict what the joint profit will be.  The first round will improve prediction using classification of dialogues into the broad categories LOW, MEDIUM, and HIGH.  The second round will attempt to predict the exact profits.  Our goal is to improve prediction without using any domain-specific features, such as the outcomes for the specific points addressed by the conversation partners in the Imai and Gelfand data.

\section{Preprocessing} % by Olivia

The data will be lowercased, punctuation removed, with non-ASCII characters removed, and tokenized.

\section{Prediction models}

% by Young
\subsection{Classification}
We will first treat prediction as a classification problem, to determine which features will produce useful results.  We will classify ranges of joint profit into LOW, MEDIUM and HIGH, using k-nearest neighbors with k=3 to make the classification.

\subsection{Regression model}  % by Peng
Once we have determined the feature set most predictive in the classification problem, we will predict joint profit more precisely.  The prediction of joint profit is a regression problem. We will compare the following regression models for this task:
\begin{enumerate}
\item Regression using SVM
\item Sparse linear regression
\item Weighted Nearest Neighbor + non-linear regression
\end{enumerate}

\section{Features}
\subsection{Feature Extraction}  % by Peng
We will test the predictive value of several features.

\begin{itemize}
\item \textbf{Uni- and bigrams:} All unigrams and bigrams of tokens occurring in the dialogue will be used as features.  Unigrams and bigrams of codes for thought units will also be used.

\item \textbf{Demographic metadata:} Mean age, negative experience, education, cultural intelligence, emotional intelligence, IQ, extroversion, openness

\item \textbf{Dialogue metadata:} Number of turns and length of dialogue: these two features would indicate whether the discussion is sufficient or not and the easiness of achieving agreement.

\item \textbf{Repetition:} Thought units, dialogues, and all statements made by a single person will be analyzed for repetition of n-grams up to trigrams.  The fact that a person is repeating a phrase by a person may be informative even if the specific phrase is not informative over several dialogues in predicting joint profit.

\end{itemize}

\subsection{Feature selection}  % by Peng
We will determine which features are the most informative according to a chi-square test and likelihood ratio test.  The best features will be used in the regression models.

\section{Evaluation and Baselines} % by Peng
\begin{itemize}

\item \textbf{Baseline}
Our first baseline will be improving the prediction of joint profit against the Imai and Gelfand result.  The next baseline will be a simple regression based only on n-gram and demographic features.

\item \textbf{Evaluation of Classification Result}
We will evaluate the performance of our model according to overall classification accuracy, precision and recall for each class (LOW, MEDIUM and HIGH).


%Consider of the problem of classifying dialogues into three different classes, 1. LOW, 2. MEDIUM and 3. HIGH, we denote the number of samples whose true label is $i$ and predicted label is $j$ as $N_{ij}$, $i,j=1,2,3$. The performance of our algorithm is evaluated with three metrics: overall classification accuracy, precision and recall for each class. The three metrics are defined as follows:

%\begin{equation*}
%accuracy = \frac{N_{11}+N_{22}+N_{33}}{\sum_{i,j}N_{ij}}
%\end{equation*}
%\begin{equation*}
%precision_{i}=\frac{N_{ii}}{N_{1i}+N_{2i}+N_{3i}}
%\end{equation*}
%\begin{equation*}
%recall_{i}=\frac{N_{ii}}{N_{i1}+N_{i2}+N_{i3}}
%\end{equation*}
%where $precision_i$ and $recall_i$ are precision and recall for class i.

\item \textbf{Evaluation of Regression Result}
Three metrics can be used to evaluate the performance of the objective quality assessment model. The first metric is Spearman rank-order correlation coefficient between predicted joint profit and true joint profit. It is related to prediction monotonicity of a model. The second metric is Pearson linear correlation coefficient between predicted joint profit and true joint Profit. It is considered as a measure of prediction accuracy of a model. The third metric is root mean squared error (rmse) between predicted joint profit and true joint profit.

\item \textbf{Cross-validation}
We will use 10-fold cross validation when obtaining any results.

\end{itemize}

\end{document}
